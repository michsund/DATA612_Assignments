# Module 4 Assignment: Data Assembly and Dealing with Missing Data

For this assignment I worked again with the State Drug Utilization data set.  Rather than merging the data with another set, I started by importing the data in 2 halves to eventually be merged together: the first 78110 rows and second 78110 rows.  I defined the first half of rows as "df1" and the second half as "df2".  Since only the first half of the data contained the column names, I displayed the columns from df1 and pasted the names for df2 so appropriate column names were also in df2.  I used head(5) to view the first 5 rows and confirm that the columns were appropriately labeled, and also to identify the first few rows of each data set.

To merge the two data sets, I used df1.append(df2, ignore_index=True) so that df2 would be appended to the end of df1, and the row index would be continuous between the two sets rather than start over at 0 for the appended data.  I named the merged data frame "combo".  I used combo.shape to verify that the appropriate number of rows and columns were present, as well as the column names to confirm that they had not changed.  I then used the iloc function to view the rows in combo where the data transitions from the first set to the second.  This way I was able to verify that the last row of df1 transitioned to df2 seamlessly, and that the merge had been successful.

Next, I looked at the columns with missing data.  I used combo.count() to view the number of values in each column and discovered that the columns "Product Name", "Latitude", "Longitude", and "Location" were all missing values (<156220 values).  Since "Product Name" was missing a very low number of values in comparison to the size of the data set (missing 54 values) I decided to drop the rows where Product Name was missing with the function combo.dropna(subset=['Product Name'])).  Next, I looked into how the Latitude/Longitude/Location values could be imputed.  By using combo.State.value_counts() I was able to see that for all rows missing the Latitude/Longitude/Location values, the State column contained the value "XX".  While not technically a null value, the State column was also missing information for these rows so I could not impute the Lat/Long/Location based on State information.  Therefore, I decided to also drop the rows missing that information with combo.dropna(subset=['Location']).  Since the data set's primary purpose is to describe drug utilization by state, entries missing the location information do not provide as much value if a corresponding state cannot be determined.  After dropping the rows missing that information, all columns had the same number of values indicating no other NaNs.
